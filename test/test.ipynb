{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mat_mat_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum grad over broadcasted dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sum_over_broadcasted_dims(grad_output, original_shape, broadcasted_shape):\n",
    "    \"\"\"\n",
    "    Compute the sum over broadcasted dimensions to match the original shape.\n",
    "    \n",
    "    Args:\n",
    "        grad_output (Tensor): The gradient output tensor with broadcasted dimensions.\n",
    "        original_shape (tuple): The shape of the original tensor before broadcasting.\n",
    "        broadcasted_shape (tuple): The broadcasted shape after broadcasting.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: The gradient tensor summed over broadcasted dimensions.\n",
    "    \"\"\"\n",
    "    # Find the broadcasted dimensions by comparing original_shape and broadcasted_shape\n",
    "    original_dims = len(original_shape)\n",
    "    broadcast_dims = len(broadcasted_shape)\n",
    "\n",
    "    # Expand original_shape to match the length of broadcasted_shape (prepend 1s)\n",
    "    if original_dims < broadcast_dims:\n",
    "        original_shape_prepend = (1,) * (broadcast_dims - original_dims) + original_shape\n",
    "    \n",
    "    # Identify which dimensions were broadcasted (i.e., size 1 in the original_shape_prepend)\n",
    "    broadcasted_dims = [i for i in range(broadcast_dims) if original_shape_prepend[i] == 1 and broadcasted_shape[i] != 1]\n",
    "    \n",
    "    # Sum over the broadcasted dimensions\n",
    "    if broadcasted_dims:\n",
    "        grad_output = torch.sum(grad_output, dim=tuple(broadcasted_dims), keepdim=False)\n",
    "    \n",
    "    # Squeeze the summed dimensions if necessary to match the original_shape\n",
    "    return grad_output.view(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "broadcasted_shape = (2, 2, 1000, 100)\n",
    "original_shape = (1, 1000, 100)\n",
    "grad_output = torch.randn(broadcasted_shape)\n",
    "\n",
    "# Compute the gradient by summing over broadcasted dimensions\n",
    "grad_input = sum_over_broadcasted_dims(grad_output, original_shape, broadcasted_shape)\n",
    "print(f\"Original Shape: {original_shape}\")\n",
    "print(f\"Broadcasted Shape: {broadcasted_shape}\")\n",
    "print(f\"Grad Output Shape: {grad_output.shape}\")\n",
    "print(f\"Summed Grad Input Shape: {grad_input.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mat_ops_dimension_check(tensor1, tensor2):\n",
    "    # Get dimensions of the input tensors\n",
    "    dim1 = tensor1.dim()\n",
    "    dim2 = tensor2.dim()\n",
    "\n",
    "    # Case 2: Both tensors are 2-dimensional (matrix-matrix product)\n",
    "    if dim1 == 2 and dim2 == 2:\n",
    "        if tensor1.size(1) != tensor2.size(0):\n",
    "            raise ValueError(f\"Size mismatch: {tensor1.size()} vs {tensor2.size()}\")\n",
    "        tensor1_broadcasted_shape = (1,) + tensor1.shape\n",
    "        tensor2_broadcasted_shape = (1,) + tensor2.shape\n",
    "\n",
    "        out_shape = ( tensor1.size(-2), tensor2.size(-1) )\n",
    "\n",
    "        return tensor1_broadcasted_shape, tensor2_broadcasted_shape, out_shape\n",
    "\n",
    "    # Case 5: Either tensor1 or tensor2 is N-dimensional (N > 2), batched matrix multiplication\n",
    "    elif (dim1 >= 2 and dim2 >= 2):\n",
    "        # Ensure broadcastability of the batch dimensions\n",
    "        # Broadcast the batch dimensions\n",
    "        try:\n",
    "            broadcasted_shape = torch.broadcast_shapes(tensor1.shape[:-2], tensor2.shape[:-2])\n",
    "        except RuntimeError as e:\n",
    "            raise ValueError(f\"Batch dimensions are not broadcastable: {tensor1.shape[:-2]} vs {tensor2.shape[:-2]}\") from e\n",
    "\n",
    "        # Ensure matrix dimensions match for multiplication\n",
    "        if tensor1.size(-1) != tensor2.size(-2):\n",
    "            raise ValueError(f\"Size mismatch in matrix dimensions: {tensor1.size()} vs {tensor2.size()}\")\n",
    "        \n",
    "        tensor1_broadcasted_shape = broadcasted_shape + tensor1.shape[-2:]\n",
    "        tensor2_broadcasted_shape = broadcasted_shape + tensor2.shape[-2:]\n",
    "\n",
    "        batch_dims = tensor1_broadcasted_shape[:-2]\n",
    "        out_shape = (*batch_dims, tensor1.size(-2), tensor2.size(-1) )\n",
    "\n",
    "        return tensor1_broadcasted_shape, tensor2_broadcasted_shape, out_shape\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimensions for batch_mat_mat_ops.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "\n",
    "t1 = torch.empty(3, 4)          # 2D tensor\n",
    "t2 = torch.empty(4, 5)          # 2D tensor\n",
    "print(mat_mat_ops_dimension_check(t1, t2))  # Expected: matrix_matrix\n",
    "\n",
    "t1 = torch.empty(5,4,1, 3, 4)       # 3D tensor\n",
    "t2 = torch.empty(4, 6)       # 3D tensor\n",
    "print(mat_mat_ops_dimension_check(t1, t2))  # Expected: batched_matrix_multiplication\n",
    "\n",
    "t1 = torch.empty(5,4,1, 3, 4)       # 3D tensor\n",
    "t2 = torch.empty(5, 4, 6)       # 3D tensor\n",
    "print(mat_mat_ops_dimension_check(t1, t2))  # Expected: batched_matrix_multiplication\n",
    "\n",
    "# Batch dimension check will fail\n",
    "t1 = torch.empty(5, 3, 4)\n",
    "t2 = torch.empty(2, 4, 6)\n",
    "try:\n",
    "    print(mat_mat_ops_dimension_check(t1, t2))  # Expected to raise an error\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((8, 64), device=device, requires_grad=requires_grad)\n",
    "b = torch.rand((64, 512), device=device, requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0,0,:], b[0,0,:]\n",
    "a.max(), b.max() , a.min(), b.min()\n",
    "# ! b.max = a.max = 1\n",
    "# ! b.min = a.min = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_mat_mat_mul(a, b):\n",
    "    # batch_dims = a.shape[:-2]\n",
    "    # out_shape = (*batch_dims, a.shape[-2], b.shape[-1])\n",
    "\n",
    "    # mat1 = a.flatten(start_dim=0, end_dim=-3)\n",
    "    # mat2 = b.flatten(start_dim=0, end_dim=-3)\n",
    "\n",
    "    return torch.matmul(input=a, other=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mat_mul(a, b):\n",
    "    # # condition = a.dim() == b.dim()\n",
    "    # # if not condition:\n",
    "    # #     raise ValueError(f'tensors a and b must have same number of dimensions')\n",
    "    # torch._check(a.dim() == b.dim() , message=f'tensors a and b must have same number of dimensions')\n",
    "    # torch._check(a.dim() >= 3 , message=f'a.dim() must be at least 3 , but {a.dim()=}')\n",
    "    # for dim in range(a.dim() - 2):\n",
    "    #     torch._check(a.shape[dim] == b.shape[dim] , message=f'tensors \"a\" and \"b\" must have same size at batch dimension: {dim=}')\n",
    "    \n",
    "    # torch._check(a.shape[-1] == b.shape[-2] , message=f'For Matrix-Matrix operation satisfy : a.shape[-1]==b.shape[-2], but {a.shape[-1]=} and {b.shape[-2]=}')\n",
    "    # torch._check(a.dtype == torch.float , message=f'tensor \"a\" must be float, but {a.dtype=}')\n",
    "    # torch._check(b.dtype == torch.float , message=f'tensor \"b\" must be float, but {b.dtype=}')\n",
    "    # torch._check(a.device == b.device , message=f'tensors \"a\" and \"b\" must be on same device, but {a.device=} and {b.device=}')\n",
    "\n",
    "    # batch_dims = a.shape[:-2]\n",
    "    # out_shape = (*batch_dims, a.shape[-2], b.shape[-1])\n",
    "\n",
    "    # a = a.flatten(start_dim=0, end_dim=-3)\n",
    "    # b = b.flatten(start_dim=0, end_dim=-3)\n",
    "    \n",
    "    out = mat_mat_ops.ops.mat_mat_mul(a,b)\n",
    "\n",
    "    # out = out.reshape(out_shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mat_mat_mul(a, b)\n",
    "expected_out = reference_mat_mat_mul(a, b)\n",
    "torch.testing.assert_close(out, expected_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape, expected_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0,0], expected_out[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_out = torch.rand_like(out)\n",
    "\n",
    "my_a_b_grad = torch.autograd.grad(out, [a, b], grad_out)\n",
    "expected_a_b_grad = torch.autograd.grad(expected_out, [a, b], grad_out)\n",
    "\n",
    "torch.testing.assert_close(my_a_b_grad, expected_a_b_grad, atol=5e-5 , rtol=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_a_b_grad[0].shape, expected_a_b_grad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_a_b_grad[1].shape, expected_a_b_grad[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_a_b_grad[0][0,0], expected_a_b_grad[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mat MAt L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_mat_mat_l1(a, b):\n",
    "    a_broadcast_shape , b_broadcast_shape, out_shape = mat_mat_ops_dimension_check(a, b)\n",
    "\n",
    "    torch._check(a.shape[-1] == b.shape[-2] , message=f'For Matrix-Matrix operation satisfy : a.shape[-1]==b.shape[-2], but {a.shape[-1]=} and {b.shape[-2]=}')\n",
    "    torch._check(a.dtype == torch.float , message=f'tensor \"a\" must be float, but {a.dtype=}')\n",
    "    torch._check(b.dtype == torch.float , message=f'tensor \"b\" must be float, but {b.dtype=}')\n",
    "    torch._check(a.device == b.device , message=f'tensors \"a\" and \"b\" must be on same device, but {a.device=} and {b.device=}')\n",
    "\n",
    "    mat1 = a.expand(a_broadcast_shape).flatten(start_dim=0, end_dim=-3)\n",
    "    mat2 = b.expand(b_broadcast_shape).flatten(start_dim=0, end_dim=-3)\n",
    "    print(mat1.shape, mat2.shape)\n",
    "    \n",
    "    B, M, K = mat1.shape\n",
    "    B, K, N = mat2.shape\n",
    "    mat2_tr = torch.transpose(input=mat2, dim0=1, dim1=2) # N,K\n",
    "    my_out = torch.empty(size=(B,M,N), device=device, dtype=torch.float)\n",
    "    for bs in range(B):\n",
    "        for m in range(M):\n",
    "            my_out[bs, m, :] = (torch.abs(mat1[bs,m,:] - mat2_tr[bs,:,:]).sum(dim=-1) ) / K # (N)\n",
    "    \n",
    "    return my_out.reshape(out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mat_l1(a, b):\n",
    "    return mat_mat_ops.ops.mat_mat_l1( a , b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mat_mat_l1(a, b) \n",
    "print(out.max() , out.min())\n",
    "# ! out.min = b.min = a.min = 0\n",
    "# ! out.max = K * (b.max or a.max) = K*1 = K\n",
    "expected_out = reference_mat_mat_l1(a, b)\n",
    "print(out.shape , expected_out.shape)\n",
    "torch.testing.assert_close(out, expected_out, atol=5e-5 , rtol=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0,0], expected_out[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, K = a.shape[-2:]\n",
    "N = b.shape[-1]\n",
    "\n",
    "grad_out = torch.rand_like(out)\n",
    "\n",
    "my_a_b_grad = torch.autograd.grad(out, [a, b], grad_out)\n",
    "expected_a_b_grad = torch.autograd.grad(expected_out, [a, b], grad_out)\n",
    "\n",
    "torch.testing.assert_close(my_a_b_grad[0], expected_a_b_grad[0]*K/N , atol=5e-5 , rtol=2e-4)\n",
    "torch.testing.assert_close(my_a_b_grad[1], expected_a_b_grad[1]*K/M , atol=5e-5 , rtol=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_a_b_grad[0][0,0], expected_a_b_grad[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"dark\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(231)\n",
    "plt.hist(a.view(-1).tolist(), bins=50, density=True);\n",
    "plt.subplot(232)\n",
    "plt.hist(b.view(-1).tolist(), bins=50, density=True);\n",
    "plt.subplot(233)\n",
    "plt.hist((out).view(-1).tolist(), bins=50, density=True);\n",
    "plt.subplot(234)\n",
    "plt.hist((grad_out).view(-1).tolist(), bins=50, density=True);\n",
    "plt.subplot(235)\n",
    "plt.hist((my_a_b_grad[0]).view(-1).tolist(), bins=50, density=True);\n",
    "plt.subplot(236)\n",
    "plt.hist((my_a_b_grad[1]).view(-1).tolist(), bins=50, density=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.4_cu12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
